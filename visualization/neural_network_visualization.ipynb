{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abs_path(n_parent: int = 0):\n",
    "    return Path('../' * n_parent).resolve()\n",
    "\n",
    "def min_max_normalization(image):\n",
    "    return (image - image.min()) / (image.max() - image.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_abs_path(1)\n",
    "model_path = path / 'models' / 'deep_geo_guessr.pt'\n",
    "images_path = path / 'visualization_examples'\n",
    "images_paths = images_path.glob('**/*.png')\n",
    "images_paths = list(images_paths)\n",
    "images_paths = [str(path) for path in images_paths]\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using {0} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_abs_path(1)\n",
    "data_path = path / 'data'\n",
    "class_names = [d.name for d in data_path.iterdir() if d.is_dir()]\n",
    "class_labels = {value:key for (key,value) in enumerate(class_names)}\n",
    "print('Labels:', class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "images = []\n",
    "for image_path in images_paths:\n",
    "    image = Image.open(image_path)\n",
    "    image = data_transform(image).to(device)\n",
    "    image = image.unsqueeze(0)\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountryClassificator(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(CountryClassificator, self).__init__()\n",
    "\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(self.model.fc.in_features, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CountryClassificator(num_classes=5)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different cnn visualization techniques\n",
    "Author: Francesco Saverio Zuppichini\\\n",
    "[Github](https://github.com/FrancescoSaverioZuppichini/A-journey-into-Convolutional-Neural-Network-visualization-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_visualizations_zuppichini.utils import *\n",
    "from cnn_visualizations_zuppichini.visualisation.core import *\n",
    "from cnn_visualizations_zuppichini.visualisation.core.utils import imshow\n",
    "from cnn_visualizations_zuppichini.visualisation.core.utils import image_net_postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 14,14\n",
    "model_traced = module2traced(model, images[0])\n",
    "vis = Weights(model, device)\n",
    "\n",
    "for i in range(1):\n",
    "    layer = model_traced[2]\n",
    "    run_vis_plot(vis, images[i], layer, ncols=4, nrows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Activation Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 24,12\n",
    "\n",
    "def get_images(outs):\n",
    "    images = [x[0] for x in outs]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = ClassActivationMapping(model, device)\n",
    "\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "outs = [vis(images[2].to(device),\n",
    "        None,\n",
    "        postprocessing=image_net_postprocessing,\n",
    "        target_class=c,\n",
    "        guide=True) for c in classes]\n",
    "\n",
    "processed_images = get_images(outs)\n",
    "\n",
    "subplot(processed_images,\n",
    "        rows_titles=['france', 'greece', 'portugal', 'spain', 'switzerland'],\n",
    "        nrows=1,\n",
    "        ncols=5,\n",
    "        parse=tensor2img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = GradCam(model, device)\n",
    "\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "outs = [\n",
    "        vis(images[2].to(device),\n",
    "        # vis(min_max_normalization(images[2]).to(device), #worse results, no warning\n",
    "        None,\n",
    "        postprocessing=image_net_postprocessing,\n",
    "        target_class=c,\n",
    "        guide=True) for c in classes]\n",
    "\n",
    "processed_images = get_images(outs)\n",
    "\n",
    "subplot(processed_images,\n",
    "        rows_titles=['france', 'greece', 'portugal', 'spain', 'switzerland'],\n",
    "        nrows=1,\n",
    "        ncols=5,\n",
    "        parse=tensor2img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradcam2crop(cam, original_img, TR):\n",
    "    b, c, w, h = original_img.shape\n",
    "    cam = cam.numpy()\n",
    "    cam -= np.min(cam)\n",
    "    cam /= np.max(cam)\n",
    "\n",
    "    cam = cv2.resize(cam, (w,h))\n",
    "    mask = cam > TR\n",
    "\n",
    "    original_img = tensor2img(image_net_postprocessing(original_img[0].squeeze()))\n",
    "\n",
    "    crop = original_img.copy()\n",
    "    crop[mask == 0] = 0\n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR =  0.4\n",
    "vis = GradCam(model, device)\n",
    "\n",
    "_ = vis(images[2],\n",
    "        None,\n",
    "        postprocessing=image_net_postprocessing)\n",
    "\n",
    "crop = gradcam2crop(vis.cam.cpu(), images[2].cpu(), TR)\n",
    "plt.imshow(crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Prism\n",
    "Author: Tomasz Szanda≈Ça\\\n",
    "[Github](https://github.com/szandala/TorchPRISM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchprism import PRISM\n",
    "\n",
    "input_batch = torch.stack([img.squeeze(0) for img in images])\n",
    "with torch.no_grad():\n",
    "    PRISM.prune_old_hooks(None)\n",
    "    PRISM.register_hooks(model)\n",
    "    output = model(input_batch)\n",
    "    output = nn.Softmax(dim=-1)(output)\n",
    "    percentages, output = torch.max(output, 1)\n",
    "    prism_maps = PRISM.get_maps().permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "\n",
    "    columns = input_batch.shape[0]\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=columns)\n",
    "    input_batch = input_batch.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "\n",
    "    for column in range(columns):\n",
    "        class_name = class_names[output[column]]\n",
    "        percentage = percentages[column]\n",
    "        ax[0][column].imshow(min_max_normalization(input_batch[column]))\n",
    "        ax[0][column].set_title(f'{class_name}\\n{percentage.item()*100:.2f}%', fontsize=22)\n",
    "        ax[0][column].axis('off')\n",
    "\n",
    "    for column in range(columns):\n",
    "        ax[1][column].imshow(prism_maps[column])\n",
    "        ax[1][column].axis('off')\n",
    "\n",
    "    fig.suptitle(f'PRISM\\n', fontsize=30)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deep_geo_guessr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6fe0407f56b7165cdf61d7ceed5246e117b7867b316dd45e1a65f953d3bf4a60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
