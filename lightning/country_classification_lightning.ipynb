{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.io import read_image\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abs_path(n_parent: int = 0):\n",
    "    return Path('../' * n_parent).resolve()\n",
    "\n",
    "def split_dataset(data_path, train_path, validate_path, test_path):\n",
    "\n",
    "    for class_dir in data_path.iterdir():\n",
    "        class_images_paths = sorted(list(class_dir.iterdir()))[:]\n",
    "\n",
    "        train_paths, test_paths = train_test_split( class_images_paths,\n",
    "                                                    test_size=0.15,\n",
    "                                                    shuffle=False,\n",
    "                                                    random_state=42)\n",
    "\n",
    "        test_paths, validate_paths = train_test_split(  test_paths,\n",
    "                                                        test_size=0.30,\n",
    "                                                        shuffle=False,\n",
    "                                                        random_state=42)\n",
    "\n",
    "        target_train_path = train_path / class_dir.name\n",
    "        target_train_path.mkdir(exist_ok=True)\n",
    "        target_validate_path = validate_path / class_dir.name\n",
    "        target_validate_path.mkdir(exist_ok=True)\n",
    "        target_test_path = test_path / class_dir.name\n",
    "        target_test_path.mkdir(exist_ok=True)\n",
    "\n",
    "        for train_image_path in train_paths:\n",
    "            shutil.copy(train_image_path, target_train_path)\n",
    "        for validate_image_path in validate_paths:\n",
    "            shutil.copy(validate_image_path, target_validate_path)\n",
    "        for test_image_path in test_paths:\n",
    "            shutil.copy(test_image_path, target_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title=''):\n",
    "    img = img / 2 + 0.35\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def display_test(dataloaders, data_transforms, class_names):\n",
    "    dataiter = iter(dataloaders['test'])\n",
    "    ex_images, ex_labels = dataiter.next()\n",
    "    # ex_images = data_transforms['train'](ex_images)\n",
    "\n",
    "    for i in range(5):\n",
    "        imshow(ex_images[i], title=class_names[ex_labels[i]])\n",
    "        # plt.imshow(  ex_images[i].permute(1, 2, 0).tonumpy()  )\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    imshow(torchvision.utils.make_grid(ex_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_abs_path(1)\n",
    "data_path = path / 'data'\n",
    "learning_path = path / 'learning_data/'\n",
    "train_path = learning_path / 'train/'\n",
    "validate_path = learning_path / 'validate/'\n",
    "test_path = learning_path / 'test/'\n",
    "train_path.mkdir(exist_ok=True, parents=True)\n",
    "validate_path.mkdir(exist_ok=True, parents=True)\n",
    "test_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "split_dataset(data_path, train_path, validate_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomChoice([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomPerspective(),\n",
    "            transforms.RandomRotation(45),\n",
    "            transforms.RandomCrop((600, 600))\n",
    "        ]),\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validate': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "keys = ['train', 'validate', 'test']\n",
    "\n",
    "image_datasets = {  x: datasets.ImageFolder(os.path.join(learning_path, x), data_transforms[x])\n",
    "                    for x in keys}\n",
    "\n",
    "dataloaders = { x: torch.utils.data.DataLoader( image_datasets[x],\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=8)\n",
    "                for x in keys}\n",
    "\n",
    "print('Train samples count:', len(image_datasets['train']))\n",
    "print('Validate samples count:', len(image_datasets['validate']))\n",
    "print('Test samples count:', len(image_datasets['test']))\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in keys}\n",
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_test(dataloaders, data_transforms, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        # self.model.conv1 = torch.nn.Conv1d(3, 64, (3, 3), bias=False)\n",
    "        self.model.fc = nn.Linear(in_features=self.model.fc.in_features, out_features=num_classes)\n",
    "\n",
    "        # self.loss = nn.BCELoss()\n",
    "        self.loss = nn.CrossEntropyLoss(weight=torch.Tensor([1.0, 1.1, 1.1, 1.0, 0.9]), reduction='mean')\n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        outputs = self(x)\n",
    "        loss = self.loss(outputs, y)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', self.accuracy(outputs, y), prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        outputs = self(x)\n",
    "        loss = self.loss(outputs, y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', self.accuracy(outputs, y), prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        outputs = self(x)\n",
    "        loss = self.loss(outputs, y)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', self.accuracy(outputs, y), prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=1e-3, momentum=0.9)\n",
    "        # optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyClassifier(num_classes=len(class_names))\n",
    "# model_name = 'lightning_sgd_46.ckpt'\n",
    "# if os.path.isfile(model_name):\n",
    "#     model = model.load_from_checkpoint(checkpoint_path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger('runs', name='SGD e=35')\n",
    "trainer = pl.Trainer(max_epochs=35, gpus=1, logger=logger)\n",
    "trainer.fit(model, train_dataloaders=dataloaders['train'], val_dataloaders=dataloaders['validate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, dataloaders=dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint('lightning_sgd_50.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "predictions = []\n",
    "for ex_images, ex_labels in dataloaders['test']:\n",
    "    results = model(ex_images)\n",
    "\n",
    "    for i in range(0, len(ex_images)):\n",
    "        pred_tensor = results[i]\n",
    "        oryg_idx = ex_labels[i]\n",
    "        img = ex_images[i]\n",
    "\n",
    "        pred_idx = int(torch.argmax(pred_tensor))\n",
    "        pred_name = class_names[pred_idx]\n",
    "        oryg_name = class_names[oryg_idx]\n",
    "\n",
    "        # title = 'true: {}, predicted: {}'.format(oryg_name, pred_name)\n",
    "        # print(title)\n",
    "        # imshow(img, title=title)\n",
    "        true.append(oryg_idx)\n",
    "        predictions.append(pred_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_filename(filename, class_names):\n",
    "    label_idx = -1\n",
    "    label_name = ''\n",
    "    for name in class_names:\n",
    "        if name in filename:\n",
    "            label_idx = class_names.index(name)\n",
    "            label_name = name\n",
    "    return label_idx, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = glob(os.path.join(path, 'learning_data\\\\test\\\\*', '*'))\n",
    "random.shuffle(path_list)\n",
    "# path_list = [path_list[0]] # if only one image - wrong output\n",
    "\n",
    "images_list = []\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "batch = torch.Tensor()\n",
    "for filename in path_list:\n",
    "    input_image = Image.open(filename)\n",
    "    input_tensor = data_transforms['test'](input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    batch = torch.cat([batch, input_batch], dim=0)\n",
    "\n",
    "    idx, name = process_filename(filename, class_names)\n",
    "    true_labels.append(name)\n",
    "    images_list.append(input_image)\n",
    "\n",
    "batch.size()\n",
    "results = model(batch)\n",
    "\n",
    "for result in results:\n",
    "    probabilities = torch.nn.functional.softmax(result, dim=0)\n",
    "    idx = int(torch.argmax(probabilities))\n",
    "    name = class_names[idx]\n",
    "    pred_labels.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL TEST\n",
    "images_count = int(input('Count of images:'))\n",
    "i = 0\n",
    "while i < images_count:\n",
    "    image = images_list[i]\n",
    "    image.show()\n",
    "    reply = input()\n",
    "    if reply != '':\n",
    "        i -= 1\n",
    "        continue\n",
    "\n",
    "    title = 'true: {}, predicted: {}'.format(true_labels[i], pred_labels[i])\n",
    "    print(title)\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a10da44cb91794881b57a0fc91695c8daa0d2aa33c8994375b52e962486c3cfb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('deep_geo_guessr': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
